{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_epilepsy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0EJyOJEC7I6",
        "outputId": "1f4b3686-9e7d-46ea-a287-6efc858ff316"
      },
      "source": [
        " from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeAo1IBqDPCy"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "X = pd.read_csv('/content/gdrive/MyDrive/toutouyaa/Copie de Copie de X_DTF.csv')\n",
        "Y = pd.read_csv('/content/gdrive/MyDrive/toutouyaa/Copie de Copie de Y_DTF.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDyX3icbDyMB"
      },
      "source": [
        "X=X.drop(columns=['Unnamed: 0'], axis=1)\n",
        "Y=Y.drop(columns=['Unnamed: 0'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "ms-V_TZGDybC",
        "outputId": "94fdc768-8cbf-4a75-d0f4-c3679c672f9b"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>361</th>\n",
              "      <th>362</th>\n",
              "      <th>363</th>\n",
              "      <th>364</th>\n",
              "      <th>365</th>\n",
              "      <th>366</th>\n",
              "      <th>367</th>\n",
              "      <th>368</th>\n",
              "      <th>369</th>\n",
              "      <th>370</th>\n",
              "      <th>371</th>\n",
              "      <th>372</th>\n",
              "      <th>373</th>\n",
              "      <th>374</th>\n",
              "      <th>375</th>\n",
              "      <th>376</th>\n",
              "      <th>377</th>\n",
              "      <th>378</th>\n",
              "      <th>379</th>\n",
              "      <th>380</th>\n",
              "      <th>381</th>\n",
              "      <th>382</th>\n",
              "      <th>383</th>\n",
              "      <th>384</th>\n",
              "      <th>385</th>\n",
              "      <th>386</th>\n",
              "      <th>387</th>\n",
              "      <th>388</th>\n",
              "      <th>389</th>\n",
              "      <th>390</th>\n",
              "      <th>391</th>\n",
              "      <th>392</th>\n",
              "      <th>393</th>\n",
              "      <th>394</th>\n",
              "      <th>395</th>\n",
              "      <th>396</th>\n",
              "      <th>397</th>\n",
              "      <th>398</th>\n",
              "      <th>399</th>\n",
              "      <th>400</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.770270</td>\n",
              "      <td>0.079666</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.733588e-02</td>\n",
              "      <td>5.366231e-02</td>\n",
              "      <td>4.032057e-02</td>\n",
              "      <td>3.932195e-02</td>\n",
              "      <td>2.594973e-02</td>\n",
              "      <td>2.701023e-02</td>\n",
              "      <td>0.169656</td>\n",
              "      <td>0.269806</td>\n",
              "      <td>0.16145</td>\n",
              "      <td>0.205622</td>\n",
              "      <td>0.135821</td>\n",
              "      <td>0.145048</td>\n",
              "      <td>0.14758</td>\n",
              "      <td>0.062679</td>\n",
              "      <td>0.052357</td>\n",
              "      <td>0.032158</td>\n",
              "      <td>0.055132</td>\n",
              "      <td>0.083053</td>\n",
              "      <td>0.050334</td>\n",
              "      <td>0.071282</td>\n",
              "      <td>0.047996</td>\n",
              "      <td>0.047721</td>\n",
              "      <td>0.122117</td>\n",
              "      <td>0.063623</td>\n",
              "      <td>0.130022</td>\n",
              "      <td>0.094257</td>\n",
              "      <td>0.059684</td>\n",
              "      <td>0.039493</td>\n",
              "      <td>0.076512</td>\n",
              "      <td>0.061235</td>\n",
              "      <td>0.112455</td>\n",
              "      <td>0.041345</td>\n",
              "      <td>0.055377</td>\n",
              "      <td>0.078716</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.770270</td>\n",
              "      <td>0.080937</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.733588e-02</td>\n",
              "      <td>5.366231e-02</td>\n",
              "      <td>4.032057e-02</td>\n",
              "      <td>3.932195e-02</td>\n",
              "      <td>2.594973e-02</td>\n",
              "      <td>2.701023e-02</td>\n",
              "      <td>0.169656</td>\n",
              "      <td>0.269806</td>\n",
              "      <td>0.16145</td>\n",
              "      <td>0.205622</td>\n",
              "      <td>0.135821</td>\n",
              "      <td>0.145048</td>\n",
              "      <td>0.14758</td>\n",
              "      <td>0.062679</td>\n",
              "      <td>0.052357</td>\n",
              "      <td>0.032158</td>\n",
              "      <td>0.055132</td>\n",
              "      <td>0.083053</td>\n",
              "      <td>0.050334</td>\n",
              "      <td>0.071282</td>\n",
              "      <td>0.047996</td>\n",
              "      <td>0.047721</td>\n",
              "      <td>0.122117</td>\n",
              "      <td>0.063623</td>\n",
              "      <td>0.130022</td>\n",
              "      <td>0.094257</td>\n",
              "      <td>0.059684</td>\n",
              "      <td>0.039493</td>\n",
              "      <td>0.076512</td>\n",
              "      <td>0.061235</td>\n",
              "      <td>0.112455</td>\n",
              "      <td>0.041345</td>\n",
              "      <td>0.055377</td>\n",
              "      <td>0.078716</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.770270</td>\n",
              "      <td>0.080937</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.733588e-02</td>\n",
              "      <td>5.366231e-02</td>\n",
              "      <td>4.032057e-02</td>\n",
              "      <td>3.932195e-02</td>\n",
              "      <td>2.594973e-02</td>\n",
              "      <td>2.701023e-02</td>\n",
              "      <td>0.169656</td>\n",
              "      <td>0.269806</td>\n",
              "      <td>0.16145</td>\n",
              "      <td>0.205622</td>\n",
              "      <td>0.135821</td>\n",
              "      <td>0.145048</td>\n",
              "      <td>0.14758</td>\n",
              "      <td>0.062679</td>\n",
              "      <td>0.052357</td>\n",
              "      <td>0.032158</td>\n",
              "      <td>0.055132</td>\n",
              "      <td>0.083053</td>\n",
              "      <td>0.050334</td>\n",
              "      <td>0.071282</td>\n",
              "      <td>0.047996</td>\n",
              "      <td>0.047721</td>\n",
              "      <td>0.122117</td>\n",
              "      <td>0.063623</td>\n",
              "      <td>0.130022</td>\n",
              "      <td>0.094257</td>\n",
              "      <td>0.059684</td>\n",
              "      <td>0.039493</td>\n",
              "      <td>0.076512</td>\n",
              "      <td>0.061235</td>\n",
              "      <td>0.112455</td>\n",
              "      <td>0.041345</td>\n",
              "      <td>0.055377</td>\n",
              "      <td>0.078716</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.770270</td>\n",
              "      <td>0.080937</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.733588e-02</td>\n",
              "      <td>5.366231e-02</td>\n",
              "      <td>4.032057e-02</td>\n",
              "      <td>3.932195e-02</td>\n",
              "      <td>2.594973e-02</td>\n",
              "      <td>2.701023e-02</td>\n",
              "      <td>0.169656</td>\n",
              "      <td>0.269806</td>\n",
              "      <td>0.16145</td>\n",
              "      <td>0.205622</td>\n",
              "      <td>0.135821</td>\n",
              "      <td>0.145048</td>\n",
              "      <td>0.14758</td>\n",
              "      <td>0.062679</td>\n",
              "      <td>0.052357</td>\n",
              "      <td>0.032158</td>\n",
              "      <td>0.055132</td>\n",
              "      <td>0.083053</td>\n",
              "      <td>0.050334</td>\n",
              "      <td>0.071282</td>\n",
              "      <td>0.047996</td>\n",
              "      <td>0.047721</td>\n",
              "      <td>0.122117</td>\n",
              "      <td>0.063623</td>\n",
              "      <td>0.130022</td>\n",
              "      <td>0.094257</td>\n",
              "      <td>0.059684</td>\n",
              "      <td>0.039493</td>\n",
              "      <td>0.076512</td>\n",
              "      <td>0.061235</td>\n",
              "      <td>0.112455</td>\n",
              "      <td>0.041345</td>\n",
              "      <td>0.055377</td>\n",
              "      <td>0.078716</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.770270</td>\n",
              "      <td>0.080937</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.733588e-02</td>\n",
              "      <td>5.366231e-02</td>\n",
              "      <td>4.032057e-02</td>\n",
              "      <td>3.932195e-02</td>\n",
              "      <td>2.594973e-02</td>\n",
              "      <td>2.701023e-02</td>\n",
              "      <td>0.169656</td>\n",
              "      <td>0.269806</td>\n",
              "      <td>0.16145</td>\n",
              "      <td>0.205622</td>\n",
              "      <td>0.135821</td>\n",
              "      <td>0.145048</td>\n",
              "      <td>0.14758</td>\n",
              "      <td>0.062679</td>\n",
              "      <td>0.052357</td>\n",
              "      <td>0.032158</td>\n",
              "      <td>0.055132</td>\n",
              "      <td>0.083053</td>\n",
              "      <td>0.050334</td>\n",
              "      <td>0.071282</td>\n",
              "      <td>0.047996</td>\n",
              "      <td>0.047721</td>\n",
              "      <td>0.122117</td>\n",
              "      <td>0.063623</td>\n",
              "      <td>0.130022</td>\n",
              "      <td>0.094257</td>\n",
              "      <td>0.059684</td>\n",
              "      <td>0.039493</td>\n",
              "      <td>0.076512</td>\n",
              "      <td>0.061235</td>\n",
              "      <td>0.112455</td>\n",
              "      <td>0.041345</td>\n",
              "      <td>0.055377</td>\n",
              "      <td>0.078716</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1643</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.355263</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.309733e-08</td>\n",
              "      <td>1.180560e-07</td>\n",
              "      <td>3.025871e-08</td>\n",
              "      <td>1.193569e-07</td>\n",
              "      <td>3.049800e-08</td>\n",
              "      <td>1.176119e-07</td>\n",
              "      <td>0.169656</td>\n",
              "      <td>0.269806</td>\n",
              "      <td>0.16145</td>\n",
              "      <td>0.205622</td>\n",
              "      <td>0.135821</td>\n",
              "      <td>0.145048</td>\n",
              "      <td>0.14758</td>\n",
              "      <td>0.062679</td>\n",
              "      <td>0.052357</td>\n",
              "      <td>0.032158</td>\n",
              "      <td>0.055132</td>\n",
              "      <td>0.083053</td>\n",
              "      <td>0.050334</td>\n",
              "      <td>0.071282</td>\n",
              "      <td>0.047996</td>\n",
              "      <td>0.047721</td>\n",
              "      <td>0.122117</td>\n",
              "      <td>0.063623</td>\n",
              "      <td>0.130022</td>\n",
              "      <td>0.094257</td>\n",
              "      <td>0.059684</td>\n",
              "      <td>0.039493</td>\n",
              "      <td>0.076512</td>\n",
              "      <td>0.061235</td>\n",
              "      <td>0.112455</td>\n",
              "      <td>0.041345</td>\n",
              "      <td>0.055377</td>\n",
              "      <td>0.078716</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1644</th>\n",
              "      <td>0.621622</td>\n",
              "      <td>0.166058</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.274015e-09</td>\n",
              "      <td>1.010828e-10</td>\n",
              "      <td>2.408357e-11</td>\n",
              "      <td>2.424514e-10</td>\n",
              "      <td>7.458161e-11</td>\n",
              "      <td>1.538929e-14</td>\n",
              "      <td>0.169656</td>\n",
              "      <td>0.269806</td>\n",
              "      <td>0.16145</td>\n",
              "      <td>0.205622</td>\n",
              "      <td>0.135821</td>\n",
              "      <td>0.145048</td>\n",
              "      <td>0.14758</td>\n",
              "      <td>0.062679</td>\n",
              "      <td>0.052357</td>\n",
              "      <td>0.032158</td>\n",
              "      <td>0.055132</td>\n",
              "      <td>0.083053</td>\n",
              "      <td>0.050334</td>\n",
              "      <td>0.071282</td>\n",
              "      <td>0.047996</td>\n",
              "      <td>0.047721</td>\n",
              "      <td>0.122117</td>\n",
              "      <td>0.063623</td>\n",
              "      <td>0.130022</td>\n",
              "      <td>0.094257</td>\n",
              "      <td>0.059684</td>\n",
              "      <td>0.039493</td>\n",
              "      <td>0.076512</td>\n",
              "      <td>0.061235</td>\n",
              "      <td>0.112455</td>\n",
              "      <td>0.041345</td>\n",
              "      <td>0.055377</td>\n",
              "      <td>0.078716</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1645</th>\n",
              "      <td>0.702703</td>\n",
              "      <td>0.513158</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.797297e-08</td>\n",
              "      <td>3.398983e-08</td>\n",
              "      <td>9.119574e-09</td>\n",
              "      <td>7.180567e-08</td>\n",
              "      <td>1.959166e-08</td>\n",
              "      <td>5.999734e-08</td>\n",
              "      <td>0.169656</td>\n",
              "      <td>0.269806</td>\n",
              "      <td>0.16145</td>\n",
              "      <td>0.205622</td>\n",
              "      <td>0.135821</td>\n",
              "      <td>0.145048</td>\n",
              "      <td>0.14758</td>\n",
              "      <td>0.062679</td>\n",
              "      <td>0.052357</td>\n",
              "      <td>0.032158</td>\n",
              "      <td>0.055132</td>\n",
              "      <td>0.083053</td>\n",
              "      <td>0.050334</td>\n",
              "      <td>0.071282</td>\n",
              "      <td>0.047996</td>\n",
              "      <td>0.047721</td>\n",
              "      <td>0.122117</td>\n",
              "      <td>0.063623</td>\n",
              "      <td>0.130022</td>\n",
              "      <td>0.094257</td>\n",
              "      <td>0.059684</td>\n",
              "      <td>0.039493</td>\n",
              "      <td>0.076512</td>\n",
              "      <td>0.061235</td>\n",
              "      <td>0.112455</td>\n",
              "      <td>0.041345</td>\n",
              "      <td>0.055377</td>\n",
              "      <td>0.078716</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1646</th>\n",
              "      <td>0.986486</td>\n",
              "      <td>0.166847</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.290333e-08</td>\n",
              "      <td>4.732699e-08</td>\n",
              "      <td>2.016586e-08</td>\n",
              "      <td>1.148077e-08</td>\n",
              "      <td>4.881674e-09</td>\n",
              "      <td>5.583148e-05</td>\n",
              "      <td>0.169656</td>\n",
              "      <td>0.269806</td>\n",
              "      <td>0.16145</td>\n",
              "      <td>0.205622</td>\n",
              "      <td>0.135821</td>\n",
              "      <td>0.145048</td>\n",
              "      <td>0.14758</td>\n",
              "      <td>0.062679</td>\n",
              "      <td>0.052357</td>\n",
              "      <td>0.032158</td>\n",
              "      <td>0.055132</td>\n",
              "      <td>0.083053</td>\n",
              "      <td>0.050334</td>\n",
              "      <td>0.071282</td>\n",
              "      <td>0.047996</td>\n",
              "      <td>0.047721</td>\n",
              "      <td>0.122117</td>\n",
              "      <td>0.063623</td>\n",
              "      <td>0.130022</td>\n",
              "      <td>0.094257</td>\n",
              "      <td>0.059684</td>\n",
              "      <td>0.039493</td>\n",
              "      <td>0.076512</td>\n",
              "      <td>0.061235</td>\n",
              "      <td>0.112455</td>\n",
              "      <td>0.041345</td>\n",
              "      <td>0.055377</td>\n",
              "      <td>0.078716</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1647</th>\n",
              "      <td>0.986486</td>\n",
              "      <td>0.166847</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.733588e-02</td>\n",
              "      <td>5.366231e-02</td>\n",
              "      <td>4.032057e-02</td>\n",
              "      <td>3.932195e-02</td>\n",
              "      <td>2.594973e-02</td>\n",
              "      <td>2.701023e-02</td>\n",
              "      <td>0.169656</td>\n",
              "      <td>0.269806</td>\n",
              "      <td>0.16145</td>\n",
              "      <td>0.205622</td>\n",
              "      <td>0.135821</td>\n",
              "      <td>0.145048</td>\n",
              "      <td>0.14758</td>\n",
              "      <td>0.062679</td>\n",
              "      <td>0.052357</td>\n",
              "      <td>0.032158</td>\n",
              "      <td>0.055132</td>\n",
              "      <td>0.083053</td>\n",
              "      <td>0.050334</td>\n",
              "      <td>0.071282</td>\n",
              "      <td>0.047996</td>\n",
              "      <td>0.047721</td>\n",
              "      <td>0.122117</td>\n",
              "      <td>0.063623</td>\n",
              "      <td>0.130022</td>\n",
              "      <td>0.094257</td>\n",
              "      <td>0.059684</td>\n",
              "      <td>0.039493</td>\n",
              "      <td>0.076512</td>\n",
              "      <td>0.061235</td>\n",
              "      <td>0.112455</td>\n",
              "      <td>0.041345</td>\n",
              "      <td>0.055377</td>\n",
              "      <td>0.078716</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1648 rows × 401 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1    2    3    4    5  ...  395  396  397  398  399  400\n",
              "0     0.770270  0.079666  0.0  1.0  0.0  0.0  ...  1.0  0.0  0.0  0.0  1.0  0.0\n",
              "1     0.770270  0.080937  1.0  1.0  1.0  0.0  ...  1.0  0.0  0.0  1.0  0.0  0.0\n",
              "2     0.770270  0.080937  1.0  1.0  1.0  0.0  ...  1.0  0.0  0.0  1.0  0.0  0.0\n",
              "3     0.770270  0.080937  1.0  1.0  1.0  0.0  ...  1.0  0.0  0.0  1.0  0.0  0.0\n",
              "4     0.770270  0.080937  1.0  1.0  1.0  0.0  ...  1.0  0.0  0.0  1.0  0.0  0.0\n",
              "...        ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
              "1643  0.500000  0.355263  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0  0.0  1.0  0.0\n",
              "1644  0.621622  0.166058  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0  1.0  0.0  0.0\n",
              "1645  0.702703  0.513158  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0  0.0  1.0  0.0\n",
              "1646  0.986486  0.166847  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  1.0  0.0  0.0\n",
              "1647  0.986486  0.166847  0.0  0.0  0.0  0.0  ...  0.0  1.0  0.0  1.0  0.0  0.0\n",
              "\n",
              "[1648 rows x 401 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "yCG2KcpUDXaK",
        "outputId": "b1b9e0d8-1ef6-407f-83bf-e5ec0eafb703"
      },
      "source": [
        "Y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1643</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1644</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1645</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1646</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1647</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1648 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Target\n",
              "0          1\n",
              "1          1\n",
              "2          1\n",
              "3          1\n",
              "4          1\n",
              "...      ...\n",
              "1643       0\n",
              "1644       0\n",
              "1645       0\n",
              "1646       0\n",
              "1647       0\n",
              "\n",
              "[1648 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-sNN_jVFVX6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G7E455YFb90"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NCAdhYpFexU",
        "outputId": "0db32fda-f2a5-4c5d-8eb9-318c8305aeeb"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "Y_train = to_categorical(y_train)\n",
        "Y_train[:3]\n",
        "print(Y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z4dLlQtFwCS",
        "outputId": "d5b53423-b31c-4d15-b86e-d89843d4cad9"
      },
      "source": [
        "#optimizer : Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 100\n",
        "output_dim = Y_train.shape[1]\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(hidden_dim, input_dim=input_dim, activation=\"tanh\"))\n",
        "model1.add(Dense(output_dim, activation=\"softmax\"))\n",
        "\n",
        "model1.compile(optimizer=optimizers.Adam(lr=0.1),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history1 = model1.fit(X_train, Y_train, validation_split=0.2, epochs=15, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "33/33 [==============================] - 1s 14ms/step - loss: 1.0366 - accuracy: 0.7158 - val_loss: 0.2234 - val_accuracy: 0.9205\n",
            "Epoch 2/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2567 - accuracy: 0.9068 - val_loss: 0.2205 - val_accuracy: 0.9280\n",
            "Epoch 3/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1806 - accuracy: 0.9183 - val_loss: 0.2511 - val_accuracy: 0.9356\n",
            "Epoch 4/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9427 - val_loss: 0.3509 - val_accuracy: 0.9205\n",
            "Epoch 5/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1374 - accuracy: 0.9527 - val_loss: 0.3817 - val_accuracy: 0.9205\n",
            "Epoch 6/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1653 - accuracy: 0.9534 - val_loss: 0.3694 - val_accuracy: 0.9356\n",
            "Epoch 7/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.9096 - val_loss: 0.5931 - val_accuracy: 0.9053\n",
            "Epoch 8/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2285 - accuracy: 0.9430 - val_loss: 0.4635 - val_accuracy: 0.9053\n",
            "Epoch 9/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1659 - accuracy: 0.9447 - val_loss: 0.6190 - val_accuracy: 0.8826\n",
            "Epoch 10/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.9356 - val_loss: 0.9279 - val_accuracy: 0.9015\n",
            "Epoch 11/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2849 - accuracy: 0.9476 - val_loss: 0.5693 - val_accuracy: 0.9015\n",
            "Epoch 12/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2159 - accuracy: 0.9586 - val_loss: 0.4657 - val_accuracy: 0.9205\n",
            "Epoch 13/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1773 - accuracy: 0.9498 - val_loss: 0.7025 - val_accuracy: 0.8939\n",
            "Epoch 14/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2563 - accuracy: 0.9463 - val_loss: 0.8254 - val_accuracy: 0.8826\n",
            "Epoch 15/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3784 - accuracy: 0.9273 - val_loss: 0.4948 - val_accuracy: 0.9205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwCwrxFDFy_m",
        "outputId": "468b427b-9db2-4fa9-e811-8b44162876f7"
      },
      "source": [
        "#Adam optimizer\n",
        "#Add another hidden layer and use the Rectifier Linear Unit\n",
        "from tensorflow.keras import activations\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(hidden_dim, input_dim=input_dim, activation=\"tanh\"))\n",
        "model2.add(Dense(hidden_dim, input_dim=input_dim, activation=activations.relu))\n",
        "model2.add(Dense(output_dim, activation=\"softmax\"))\n",
        "\n",
        "model2.compile(optimizer=optimizers.Adam(lr=0.1),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history2=model2.fit(x=X_train, y=Y_train, validation_split=0.2, epochs=15,batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "33/33 [==============================] - 1s 8ms/step - loss: 2.7671 - accuracy: 0.7381 - val_loss: 3.8727 - val_accuracy: 0.8447\n",
            "Epoch 2/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.7493 - accuracy: 0.8651 - val_loss: 1.9647 - val_accuracy: 0.9280\n",
            "Epoch 3/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8789 - accuracy: 0.9128 - val_loss: 1.1246 - val_accuracy: 0.9356\n",
            "Epoch 4/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8806 - accuracy: 0.8865 - val_loss: 2.2407 - val_accuracy: 0.9242\n",
            "Epoch 5/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9067 - accuracy: 0.9116 - val_loss: 1.4881 - val_accuracy: 0.9205\n",
            "Epoch 6/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.9234 - val_loss: 1.8827 - val_accuracy: 0.9015\n",
            "Epoch 7/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7276 - accuracy: 0.9160 - val_loss: 2.0810 - val_accuracy: 0.8977\n",
            "Epoch 8/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6471 - accuracy: 0.9162 - val_loss: 1.8527 - val_accuracy: 0.9280\n",
            "Epoch 9/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.9361 - val_loss: 3.5781 - val_accuracy: 0.9280\n",
            "Epoch 10/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.9299 - val_loss: 1.8197 - val_accuracy: 0.9091\n",
            "Epoch 11/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7219 - accuracy: 0.9281 - val_loss: 2.3882 - val_accuracy: 0.8902\n",
            "Epoch 12/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7092 - accuracy: 0.9160 - val_loss: 3.2930 - val_accuracy: 0.8788\n",
            "Epoch 13/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9516 - accuracy: 0.9293 - val_loss: 4.0246 - val_accuracy: 0.8788\n",
            "Epoch 14/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9731 - accuracy: 0.9300 - val_loss: 13.9815 - val_accuracy: 0.8485\n",
            "Epoch 15/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 2.8843 - accuracy: 0.9086 - val_loss: 10.4612 - val_accuracy: 0.8826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_7uthmXF12E",
        "outputId": "eeb8ad89-17ad-4814-c173-0d124a9a6e5e"
      },
      "source": [
        "#SGD optimizer with a learning rate=0.01\n",
        "optimizers.SGD?\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 100\n",
        "output_dim = Y_train.shape[1]\n",
        "\n",
        "model4 = Sequential()\n",
        "model4.add(Dense(hidden_dim, input_dim=input_dim, activation=\"tanh\"))\n",
        "model4.add(Dense(output_dim, activation=\"softmax\"))\n",
        "\n",
        "model4.compile(optimizer=optimizers.SGD(lr=0.01),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history4= model4.fit(X_train, Y_train, validation_split=0.2, epochs=15, batch_size=32) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6634 - accuracy: 0.6496 - val_loss: 0.4754 - val_accuracy: 0.8333\n",
            "Epoch 2/15\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8247 - val_loss: 0.3734 - val_accuracy: 0.8902\n",
            "Epoch 3/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8809 - val_loss: 0.3163 - val_accuracy: 0.9053\n",
            "Epoch 4/15\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8837 - val_loss: 0.2797 - val_accuracy: 0.9091\n",
            "Epoch 5/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2687 - accuracy: 0.9153 - val_loss: 0.2542 - val_accuracy: 0.9129\n",
            "Epoch 6/15\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.9166 - val_loss: 0.2360 - val_accuracy: 0.9280\n",
            "Epoch 7/15\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.2321 - accuracy: 0.9173 - val_loss: 0.2222 - val_accuracy: 0.9242\n",
            "Epoch 8/15\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.9239 - val_loss: 0.2115 - val_accuracy: 0.9205\n",
            "Epoch 9/15\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.1998 - accuracy: 0.9234 - val_loss: 0.2033 - val_accuracy: 0.9318\n",
            "Epoch 10/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1838 - accuracy: 0.9436 - val_loss: 0.1970 - val_accuracy: 0.9356\n",
            "Epoch 11/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9526 - val_loss: 0.1918 - val_accuracy: 0.9356\n",
            "Epoch 12/15\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9590 - val_loss: 0.1875 - val_accuracy: 0.9356\n",
            "Epoch 13/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1595 - accuracy: 0.9594 - val_loss: 0.1840 - val_accuracy: 0.9356\n",
            "Epoch 14/15\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.1597 - accuracy: 0.9576 - val_loss: 0.1809 - val_accuracy: 0.9356\n",
            "Epoch 15/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.9689 - val_loss: 0.1787 - val_accuracy: 0.9356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hu0w5l8CF4rV",
        "outputId": "0423d4b0-5dfb-41f0-f854-dbd92c15c749"
      },
      "source": [
        "#SGD optimizer with a learning rate=0.1\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "hidden_dim = 100\n",
        "output_dim = Y_train.shape[1]\n",
        "\n",
        "model5 = Sequential()\n",
        "model5.add(Dense(hidden_dim, input_dim=input_dim, activation=\"tanh\"))\n",
        "model5.add(Dense(output_dim, activation=\"softmax\"))\n",
        "\n",
        "model5.compile(optimizer=optimizers.SGD(lr=0.1),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history5 = model5.fit(X_train, Y_train, validation_split=0.2, epochs=15, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.4946 - accuracy: 0.7708 - val_loss: 0.1999 - val_accuracy: 0.9356\n",
            "Epoch 2/15\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.1725 - accuracy: 0.9448 - val_loss: 0.1750 - val_accuracy: 0.9280\n",
            "Epoch 3/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1360 - accuracy: 0.9568 - val_loss: 0.1633 - val_accuracy: 0.9356\n",
            "Epoch 4/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9582 - val_loss: 0.1645 - val_accuracy: 0.9356\n",
            "Epoch 5/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0898 - accuracy: 0.9707 - val_loss: 0.1669 - val_accuracy: 0.9318\n",
            "Epoch 6/15\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.9746 - val_loss: 0.1771 - val_accuracy: 0.9318\n",
            "Epoch 7/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9774 - val_loss: 0.1842 - val_accuracy: 0.9318\n",
            "Epoch 8/15\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.9813 - val_loss: 0.1962 - val_accuracy: 0.9242\n",
            "Epoch 9/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9666 - val_loss: 0.1996 - val_accuracy: 0.9242\n",
            "Epoch 10/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9796 - val_loss: 0.2039 - val_accuracy: 0.9205\n",
            "Epoch 11/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9808 - val_loss: 0.2109 - val_accuracy: 0.9205\n",
            "Epoch 12/15\n",
            "33/33 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9795 - val_loss: 0.2191 - val_accuracy: 0.9167\n",
            "Epoch 13/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9793 - val_loss: 0.2246 - val_accuracy: 0.9129\n",
            "Epoch 14/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9808 - val_loss: 0.2341 - val_accuracy: 0.9129\n",
            "Epoch 15/15\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9875 - val_loss: 0.2372 - val_accuracy: 0.9129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvvPlkg9F877",
        "outputId": "c996f1ba-69ad-49e3-91c0-e49135a0a778"
      },
      "source": [
        "Y_predict=model5.predict_classes(X_test) #compute predictions on test set\n",
        "Y_predict\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9UK4jYNF_zV",
        "outputId": "53a71c91-9177-41b8-e72c-efb7901ee11a"
      },
      "source": [
        "history5.history #display the values of the loss function,the accuracy and the val_loss we obtained for each epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.8415559530258179,\n",
              "  0.9440227746963501,\n",
              "  0.9573054909706116,\n",
              "  0.9667931795120239,\n",
              "  0.9696394801139832,\n",
              "  0.9743832945823669,\n",
              "  0.9743832945823669,\n",
              "  0.9762808084487915,\n",
              "  0.9753320813179016,\n",
              "  0.9781783819198608,\n",
              "  0.9781783819198608,\n",
              "  0.9762808084487915,\n",
              "  0.9791271090507507,\n",
              "  0.98197340965271,\n",
              "  0.98197340965271],\n",
              " 'loss': [0.37984326481819153,\n",
              "  0.16998277604579926,\n",
              "  0.12549874186515808,\n",
              "  0.10402494668960571,\n",
              "  0.09032586216926575,\n",
              "  0.08048863708972931,\n",
              "  0.07261541485786438,\n",
              "  0.06689244508743286,\n",
              "  0.06247810274362564,\n",
              "  0.0577964149415493,\n",
              "  0.055581629276275635,\n",
              "  0.052693985402584076,\n",
              "  0.04989980533719063,\n",
              "  0.04758154973387718,\n",
              "  0.0455392450094223],\n",
              " 'val_accuracy': [0.935606062412262,\n",
              "  0.9280303120613098,\n",
              "  0.935606062412262,\n",
              "  0.935606062412262,\n",
              "  0.9318181872367859,\n",
              "  0.9318181872367859,\n",
              "  0.9318181872367859,\n",
              "  0.9242424368858337,\n",
              "  0.9242424368858337,\n",
              "  0.9204545617103577,\n",
              "  0.9204545617103577,\n",
              "  0.9166666865348816,\n",
              "  0.9128788113594055,\n",
              "  0.9128788113594055,\n",
              "  0.9128788113594055],\n",
              " 'val_loss': [0.19988444447517395,\n",
              "  0.1749643236398697,\n",
              "  0.16334927082061768,\n",
              "  0.16446085274219513,\n",
              "  0.1669105589389801,\n",
              "  0.1770932972431183,\n",
              "  0.1841677725315094,\n",
              "  0.19615013897418976,\n",
              "  0.19963078200817108,\n",
              "  0.20390142500400543,\n",
              "  0.21094267070293427,\n",
              "  0.21905559301376343,\n",
              "  0.22461682558059692,\n",
              "  0.23412460088729858,\n",
              "  0.23723843693733215]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlniUookGBs3",
        "outputId": "e2f8dcab-928b-4400-c876-ff287380e7d0"
      },
      "source": [
        "history5.history['accuracy'] #display the values of the accuracy we obtained for each epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7813953757286072,\n",
              " 0.8062015771865845,\n",
              " 0.804651141166687,\n",
              " 0.804651141166687,\n",
              " 0.8031007647514343,\n",
              " 0.8062015771865845,\n",
              " 0.8077519536018372,\n",
              " 0.8077519536018372,\n",
              " 0.8093023300170898,\n",
              " 0.8077519536018372,\n",
              " 0.8124030828475952,\n",
              " 0.8077519536018372,\n",
              " 0.8139534592628479,\n",
              " 0.8186046481132507,\n",
              " 0.8201550245285034]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut7yP5e1GEFP",
        "outputId": "ec0d3e0a-7709-4c1c-9d96-e95f014c4482"
      },
      "source": [
        "#calculate the average accuracy\n",
        "np.mean(history5.history['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9636938571929932"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V40kDbI5GLrH"
      },
      "source": [
        "***********************************************************"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUQDEfM7P9lE"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "\n",
        "model_rnn = Sequential()\n",
        "model_rnn.add(LSTM(128, input_shape=(X_train.shape[1:]), activation='relu', return_sequences=True))\n",
        "model_rnn.add(BatchNormalization())\n",
        "model_rnn.add(Dropout(0.2))\n",
        "\n",
        "model_rnn.add(LSTM(128, activation='relu'))\n",
        "model_rnn.add(BatchNormalization())\n",
        "model_rnn.add(Dropout(0.1))\n",
        "\n",
        "model_rnn.add(Dense(32, activation='relu'))\n",
        "model_rnn.add(BatchNormalization())\n",
        "model_rnn.add(Dropout(0.2))\n",
        "\n",
        "model_rnn.add(Dense(1, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWYltkzLR3OO",
        "outputId": "79f4e3a1-26a2-4dd2-8463-bd318b951793"
      },
      "source": [
        "model_rnn.compile(optimizer=Adam(0.001),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy', 'AUC', 'Recall', 'Precision'])\n",
        "mod_rnn_fitted = model_rnn.fit(X_train, y_train, epochs=6, \n",
        "                    validation_data=(X_test, y_test))\n",
        "history_model_rnn = model_rnn.fit(X_train, Y_train, validation_split=0.2, epochs=15, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 0.4272 - accuracy: 0.8016 - val_loss: 0.1424 - val_accuracy: 0.9500\n",
            "Epoch 2/15\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1260 - accuracy: 0.9819 - val_loss: 0.1090 - val_accuracy: 0.9500\n",
            "Epoch 3/15\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1109 - accuracy: 0.9836 - val_loss: 0.0972 - val_accuracy: 0.9625\n",
            "Epoch 4/15\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0884 - accuracy: 0.9804 - val_loss: 0.0926 - val_accuracy: 0.9625\n",
            "Epoch 5/15\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1172 - accuracy: 0.9669 - val_loss: 0.0893 - val_accuracy: 0.9625\n",
            "Epoch 6/15\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0871 - accuracy: 0.9801 - val_loss: 0.0879 - val_accuracy: 0.9500\n",
            "Epoch 7/15\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0864 - accuracy: 0.9779 - val_loss: 0.0876 - val_accuracy: 0.9500\n",
            "Epoch 8/15\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0686 - accuracy: 0.9832 - val_loss: 0.0868 - val_accuracy: 0.9500\n",
            "Epoch 9/15\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0660 - accuracy: 0.9796 - val_loss: 0.0861 - val_accuracy: 0.9500\n",
            "Epoch 10/15\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0663 - accuracy: 0.9730 - val_loss: 0.0863 - val_accuracy: 0.9500\n",
            "Epoch 11/15\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0787 - accuracy: 0.9707 - val_loss: 0.0852 - val_accuracy: 0.9500\n",
            "Epoch 12/15\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0860 - accuracy: 0.9686 - val_loss: 0.0838 - val_accuracy: 0.9500\n",
            "Epoch 13/15\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0682 - accuracy: 0.9750 - val_loss: 0.0841 - val_accuracy: 0.9500\n",
            "Epoch 14/15\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0621 - accuracy: 0.9801 - val_loss: 0.0827 - val_accuracy: 0.9500\n",
            "Epoch 15/15\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0421 - accuracy: 0.9873 - val_loss: 0.0827 - val_accuracy: 0.9500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCvwKwR9LDn3",
        "outputId": "ec0d3e0a-7709-4c1c-9d96-e95f014c4482"
      },
      "source": [
        "np.mean(history_model_rnn.history['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9636938571929932"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    }
  ]
}