{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EDF_features__extraction.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"HuLBeS8GlMz8"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4mWNfKwZ60ci"},"source":["#LR :liste des liens des  fichiers\n","#LR_EDF  :liste des liens des  fichiersedf des patients\n","#LR_EDF_EPL  :liste des liens des  fichiersedf des patients epileptique\n","#LR_EDF_NEPL :liste des liens des  fichiersedf des patients non epileptique\n","#L_EDF :liste  des fichiers edf des patients\n","#L_EDF_EPL :liste  des fichiers edf des patients epileptique\n","#L_EDF_NEPL :liste  des fichiers edf des patients non epileptique\n","#LID_EDF  : liste des ID des fichiers edf des patients\n","#LID_EDF_EPL : liste des ID des fichiers edf des patients epileptique\n","#LID_EDF_NEPL : liste des ID des fichiers edf des patients non epileptique"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dXhOeCO4uh7F"},"source":[" from google.colab import drive\n","\n","drive.mount(\"/content/gdrive\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eviiFH8ywo43"},"source":["!pip install mne"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AsZJt2fIwDVZ"},"source":["import mne\n","import pandas as pd\n","import matplotlib.pyplot as plt\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IJtyqk41wiro"},"source":["import os\n","#liste des liens des fichiers et dossiers :\n","os.chdir(r'/content/gdrive/MyDrive/Données_internes/edf')\n","LR=[]\n","for root, dirs, files in os.walk(\".\", topdown = False):\n","   for name in files:\n","      #print(os.path.join(root, name))\n","      LR.append(os.path.join(root,name))\n","   #for name in dirs:\n","      #print(os.path.join(root, name))\n","LR ;"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5J8noJ0OxK0g"},"source":["####################################################\n","#                                                  #\n","#            EDF   EPILEPSY                        #\n","#                                                  #\n","####################################################   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ErHDrv5Gyx6i"},"source":["#liste des liens  fichiers txt des patients epileptiques\n","os.chdir(r'/content/gdrive/MyDrive/Données_internes/edf')\n","LR_EDF_EPL=[]\n","for root, dirs, files in os.walk(\"./epilepsy\", topdown = False):\n","   for name in files:\n","      #print(os.path.join(root, name))\n","      if name.endswith(\"edf\"):\n","          LR_EDF_EPL.append(os.path.join(root,name))\n","   #for name in dirs:\n","      #print(os.path.join(root, name))\n","LR_EDF_EPL ;"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C_dvK82a00BY"},"source":["len(LR_EDF_EPL) ;"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ngK0G08Dy7XO"},"source":["#liste des fichiers edf des patients épileptiques\n","L_EDF_EPL = []\n","\n","for root,dirs,files in os.walk(r'/content/gdrive/MyDrive/Données_internes/edf/epilepsy'):\n","  for filename in files:\n","       if filename.endswith(\"edf\"):\n","         L_EDF_EPL.append(filename)\n","\n","L_EDF_EPL ;\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vaov3KJSzUZF"},"source":["#liste des ID des fichiers txt des patients   épileptiques\n","LID_EDF_EPL=[]\n","for i in range(len(L_EDF_EPL)):\n","    FILE = L_EDF_EPL[i];\n","    ID = FILE[0:FILE.index('.edf')];\n","    LID_EDF_EPL.append(ID);\n","\n","LID_EDF_EPL ;"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JTMx_iTQ6pRP"},"source":["#liste des liens  fichiers txt des patients epileptiques de configuration 01 AR:\n","os.chdir(r'/content/gdrive/MyDrive/Données_internes/edf')\n","LR_EDF_EPL_01AR =[]\n","for root, dirs, files in os.walk(\"./epilepsy/01_tcp_ar\", topdown = False):\n","   for name in files:\n","      #print(os.path.join(root, name))\n","      if name.endswith(\"edf\"):\n","          LR_EDF_EPL_01AR.append(os.path.join(root,name))\n","   #for name in dirs:\n","      #print(os.path.join(root, name))\n","LR_EDF_EPL_01AR "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8uyyoYYkzjpc"},"source":["####################################################\n","#                                                  #\n","#            EDF   NO EPILEPSY                     #\n","#                                                  #\n","####################################################  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NP5-CK9Yz9sT"},"source":["#liste des liens  fichiers edf des patients non epileptiques\n","os.chdir(r'/content/gdrive/MyDrive/Données_internes/edf')\n","LR_EDF_NEPL=[]\n","for root, dirs, files in os.walk(\"./no_epilepsy\", topdown = False):\n","   for name in files:\n","      #print(os.path.join(root, name))\n","      if name.endswith(\".edf\"):\n","          LR_EDF_NEPL.append(os.path.join(root,name))\n","   #for name in dirs:\n","      #print(os.path.join(root, name))\n","LR_EDF_NEPL ;"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GOXscsGU0m-S"},"source":["len(LR_EDF_NEPL) ;"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZJBI568B0waA"},"source":["\n","#liste des fichiers edf des patients no  épileptiques\n","L_EDF_NEPL = []\n","\n","for root,dirs,files in os.walk(r'/content/gdrive/MyDrive/Données_internes/edf/no_epilepsy'):\n","  for filename in files:\n","       if filename.endswith(\".edf\"):\n","         L_EDF_NEPL.append(filename)\n","\n","L_EDF_NEPL ;\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WmtzlZfX1UFH"},"source":["#liste des ID des fichiers edf des patients no  épileptiques\n","LID_EDF_NEPL=[]\n","for i in range(len(L_EDF_NEPL)):\n","    FILE = L_EDF_NEPL[i];\n","    ID = FILE[0:FILE.index('.edf')];\n","    LID_EDF_NEPL.append(ID);\n","\n","LID_EDF_NEPL  ;"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SF3Ikkee1YwH"},"source":["##################################################\n","##################################################\n","##################################################\n","#liste des liens des fichiers txt des patients\n","LR_EDF = LR_EDF_EPL + LR_EDF_NEPL\n","#liste  des fichiers txt des patients\n","L_EDF = L_EDF_EPL + L_EDF_NEPL\n","#liste des ID des fichiers txt des patients\n","LID_EDF = LID_EDF_EPL + LID_EDF_NEPL \n","##################################################\n","##################################################\n","##################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"928EdAqQ2Xzp"},"source":["print(len(LR_EDF)) ;\n","print(len(L_EDF)) ;\n","print(len(LID_EDF)) ;"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nTRhug5A2i84"},"source":["Len = LID_EDF "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"05FYzHeBNDpd"},"source":["####################################################\n","#                                                  #\n","#                 CHANNELS                         #\n","#                                                  #\n","####################################################  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"etIhrB7N2o2f"},"source":["def channels_file(filename):  #fonction qui retourne les channels d'un fichier donné passé en paramètre\n","    file = filename\n","    data = mne.io.read_raw_edf(file)\n","    channels = data.ch_names\n","    return channels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fwlxo2I3Eu8I"},"source":["liste des chaines eeg :\n","LCH =[]\n","for file in LR_EDF :\n","  Ch = channels_file(file) \n","  for i in Ch :\n","    if (i not in LCH ) :\n","      LCH.append(i)\n","LCH\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"szM8A458j2qg"},"source":["coef=['A6', 'D6', 'D5', 'D4', 'D3', 'D2', 'D1']\n","LFL = ['mean_abs','std', 'mean','ratio' ,'log_sum' ] \n","LCH= ['EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', 'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF', 'EEG T6-REF', 'EEG A1-REF', 'EEG A2-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF', 'EEG ROC-REF', 'EEG LOC-REF', 'EEG EKG1-REF', 'EEG T1-REF', 'EEG T2-REF', 'PHOTIC-REF', 'IBI', 'BURSTS', 'SUPPR', 'EEG C3P-REF', 'EEG C4P-REF', 'EEG SP1-REF', 'EEG SP2-REF', 'EMG-REF', 'EEG 31-REF', 'EEG 32-REF', 'EEG 26-REF', 'EEG 27-REF', 'EEG 28-REF', 'EEG 29-REF', 'EEG 30-REF', 'EEG PG1-REF', 'EEG PG2-REF', 'EEG FP1-LE', 'EEG FP2-LE', 'EEG F3-LE', 'EEG F4-LE', 'EEG C3-LE', 'EEG C4-LE', 'EEG A1-LE', 'EEG A2-LE', 'EEG P3-LE', 'EEG P4-LE', 'EEG O1-LE', 'EEG O2-LE', 'EEG F7-LE', 'EEG F8-LE', 'EEG T3-LE', 'EEG T4-LE', 'EEG T5-LE', 'EEG T6-LE', 'EEG FZ-LE', 'EEG CZ-LE', 'EEG PZ-LE', 'EEG OZ-LE', 'EEG PG1-LE', 'EEG PG2-LE', 'EEG EKG-LE', 'EEG SP2-LE', 'EEG SP1-LE', 'EEG RLC-LE', 'EEG LUC-LE', 'EEG 30-LE', 'EEG T1-LE', 'EEG T2-LE', 'PHOTIC PH', 'EEG 28-LE', 'EEG 29-LE', 'EEG 26-LE', 'EEG 27-LE', 'EEG 31-LE', 'EEG 32-LE', 'DC1-DC', 'DC2-DC', 'DC3-DC', 'DC4-DC', 'DC5-DC', 'DC6-DC', 'DC7-DC', 'DC8-DC', 'EEG 23-LE', 'EEG 24-LE', 'EEG 20-REF', 'EEG 21-REF', 'EEG 22-REF', 'EEG 23-REF', 'EEG 24-REF', 'EEG 25-REF', 'EDF ANNOTATIONS']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ulgk_Tz-L4Dy"},"source":["len(LCH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g2vXMvR_-b5G"},"source":["#for file in LR_EDF :\n","# Ch = channels_file(file) \n","# print(\"\\n --------------- \\n chanells of \",file,\" : \", Ch)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5QMrrVI7kqo3"},"source":["LF =[]\n","col =\"\"\n","\n","for ch in range(0,len(LCH)):\n","  for ft in range(1,len(coef)) :\n","     for fl in range(len(LFL)) :\n","\n","          col_name =LCH[ch]+'_' + coef[ft]+'_' + LFL[fl]  \n","\n","          LF.append(col_name) \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ewUiFlTMpkQb"},"source":["####################################################\n","#                                                  #\n","#                 DataFrame                        #\n","#                                                  #\n","####################################################  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hByutO1jNT_S"},"source":["#creation DATAF + channels \n","DATACHN =pd.DataFrame(columns=['ID']+LF)\n","DATACHN"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNDbFA1upjR9"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MZSTXj4RpifD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JdYcoH6gUIPG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Er3l-s3cU4gL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xN3fHJL-PfvB"},"source":["DATACHN['ID']=LID_EDF\n","DATACHN\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uoxeB0p8qHtF"},"source":["####################################################\n","#                                                  #\n","#                   FIlTRING                       #\n","#                                                  #\n","####################################################  \n"," "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kx01BOQ06Fy0"},"source":["#Butterworth filter (Low pass filter)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"amcJ_UfD7gRs"},"source":["def filtrage_file_channel(file,i):  #i:channel\n","    data = mne.io.read_raw_edf(file)\n","    raw_data = data.get_data()\n","    cutoff=40.\n","    fs=1000\n","    nyq = 0.5 * fs\n","    low = cutoff / nyq\n","    b, a = scipy.signal.butter(3, low, btype='low', analog=False)\n","    sig=data.get_data()[i]\n","    filtered_signal1=scipy.signal.filtfilt(b,a,sig,axis=0)\n","    return filtered_signal1   #retourne un array (un signal filtré)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1dt5bmzSr8ql"},"source":["#FFT filter (smoothing filter)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qMumkWS7j07"},"source":["import numpy as np\n","import scipy.fftpack\n","def filtrage_file_channel_FFT(i):  #i:channel\n","   # data = mne.io.read_raw_edf(file)\n","   # raw_data = data.get_data()\n","    sig=i\n","    \n","    sig_fft = scipy.fftpack.fft(sig)\n","    time_step = 0.02\n","    period = 5.\n","    power = np.abs(sig_fft)**2\n","    sample_freq = scipy.fftpack.fftfreq(sig.size, d=time_step)\n","    pos_mask = np.where(sample_freq > 0)\n","    freqs = sample_freq[pos_mask]\n","    peak_freq = freqs[power[pos_mask].argmax()]\n","    np.allclose(peak_freq, 1./period)\n","    \n","    high_freq_fft = sig_fft.copy()\n","    high_freq_fft[np.abs(sample_freq) > peak_freq] = 0\n","    filtered_sig = scipy.fftpack.ifft(high_freq_fft)\n","    return filtered_sig  #retourne un array qui représente le résultat du signal filtré sur un channel i "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"by_fbivjnzeV"},"source":["#filt2=filtrage_file_channel_FFT(filt)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MVhUXVbFnz8M"},"source":["##########################################\n","#                                        #\n","#            DECOMPOS                    #\n","#                                        #\n","##########################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d_VP4ycWn0Uc"},"source":["import pandas as pd \n","from pywt import wavedec\n","def decompose_signal_channel(filt2,i):\n","    #data = mne.io.read_raw_edf(file)\n","   # raw_data = data.get_data()\n","    channels = channels_file(rf) #file in in put \n","    data1=filt2\n","    #channel_name=channels[channel]\n","    print(channels[i])\n","    # number of levels we are interested in\n","    level = 6\n","\n","    # transpose the data because its a time-series package\n","    data_t = data1.transpose()\n","\n","   # get the wavelet coefficients at each level in a list\n","    coeffs_list = wavedec(data1, wavelet='db4', level=level)\n","   \n","    coefficients=coef\n","    \n","   \n","    L=[[]]\n","    for i in range(len(coefficients)):\n","      array=coeffs_list[i].flatten()\n","      list1=array.tolist()\n","      L.append(list1)\n","        \n","    L.remove(L[0])\n","    df = pd.DataFrame(columns=coef)\n","    Series_coefficients=[]\n","    for  i in range(len(coeffs_list)):\n","     Series_coefficients.append(pd.Series(L[i]))\n","    \n","    \n","    for i in range(len(coefficients)):\n","      df[coefficients[i]]=Series_coefficients[i]\n","    \n","    return(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cjo-qRzI7PsH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ww-sDQFDrKL"},"source":["#rf=LR_EDF[17] "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tk8y7Nap6Uog"},"source":["#df_test= Fl_Ft(rf,'log_sum')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PNcd9FUdES3k"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HdUEqqPhlQl1"},"source":["#####################################################################################################################################        \n","#                                                                                                                                   #         \n","#                    ###################################.  DWT Features.   ##########################################               #\n","#                                                                                                                                   #        \n","#                                                                                                                                   #        \n","#     There are 5 features that come from the wavelet transform that I will focus on from the DWT:                 #  \n","#                                                                                                                                   #\n","#     * Log-Sum of the wavelet transform.                                                                                           #\n","#     * Mean of the absolute values of the coefficients in each sub-band                                                            #\n","#     * Average power of the wavelet coefficients in each sub-band                                                                  #\n","#     * Standard deviation of the coefficients in each sub-band.                                                                    #\n","#     *  Ratio of the absolute mean values of adjacent sub-bands.                                                                   #\n","#                                                                                                                                   #\n","#####################################################################################################################################    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DHuvMITi_2F0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lc8W0xF_Mz_I"},"source":["def ave(data, output=False):\n","    # get the mean\n","    mean_data = data.mean()\n","    return(mean_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iGFOM6pbmhlf"},"source":["##########################################\n","#                                        #\n","#           Log Sum                      #\n","#                                        #\n","##########################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CPxv3VMJj4E-"},"source":["# #def minus_small(data):    \n","#  # # find the smallest value for each data column (channel)...\n","#   #min_val = data.min()\n","#   ## ...and subtract it from all the data in the column and add one\n","#   #data = data.subtract(min_val).add(1)\n","\n","#   #return data\n","# def minus_small(data):    \n","#   # find the smallest value for each data column (channel)...\n","#   min_val = data.min()\n","#   # ...and subtract it from all the data in the column and add one\n","#   List_one=[1 for i in range(2604)]\n","#   Series_one=pd.Series(List_one)\n","#   data_substract = np.subtract(data,min_val)\n","#   data_modified=np.add(data_substract,List_one)\n","\n","\n","#   return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SSMfUpGUn3cF"},"source":["# def log_sum(data, output=False):\n","   \n","#     absolute_sums = data.sum()\n","#     # ...and subtract it from all the data in the column and add one\n","#     absolute_sums_minus = minus_small(absolute_sums)\n","#     # find the log of each elecment (datapoint)\n","#     absolute_sums_minus2=pd.DataFrame(columns='test')\n","#     absolute_sums_minus2['test'] =absolute_sums_minus\n","#     absolute_sums_log = absolute_sums_minus2.apply(np.log)\n","   \n","#     asl=absolute_sums_log.tolist()\n","#     a=asl.sum()\n","    \n","#     return a"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Av1hvV_ftAkS"},"source":["# def l_sum (df1) :  #retourne une liste des means abs a partir d une channel decompposee (dataframe )\n","#     ls=[]\n","#     coeffic =coef[1:]\n","#     for i in range(len(coeffic)) :\n","#        t=log_sum(df1[coeffic[i]])\n","#        ls.append(t)\n","#     return ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ysdhY4MYoO03"},"source":["##########################################\n","#                                        #\n","#            Average power               #\n","#                                        #\n","##########################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LBgnAarGkKd4"},"source":["\n","def ave(data, output=False):\n","    # get the mean\n","    mean_data = data.mean()\n","\n","    \n","    return mean_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yyhDhdOFsprH"},"source":["def mn (df1) :  #retourne une liste des means abs a partir d une channel decompposee (dataframe )\n","    coeffic =coef[1:]\n","    meand=[]\n","    for i in range(len(coeffic)) :\n","       t=ave(df1[coeffic[i]])\n","       meand.append(t)\n","    return meand"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CVElYXv7h5OO"},"source":["##########################################\n","#                                        #\n","#            mean abs.                   #\n","#                                        #\n","##########################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wOndRWv5nyT2"},"source":["def mean_abs(data, output=False):\n","    # get the mean of the absolute values\n","    mean_abs_data = data.abs().mean()\n","    return mean_abs_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EaeK_Hr6xFiM"},"source":["def m_abs(df1) :  #retourne une liste des means abs a partir d une channel decompposee (dataframe )\n","    coeffic =coef[1:]\n","    LmAbs=[]\n","    for i in range(len(coeffic)) :\n","       t=mean_abs(df1[coeffic[i]])\n","       LmAbs.append(t)\n","    return LmAbs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K1uKGXriQKtw"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G2TahnzdNEn_"},"source":["##########################################\n","#                                        #\n","#                 STD                    #\n","#                                        #\n","##########################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Ju42cL6mjSy"},"source":["def coeff_std(data, output=False):\n","    # get the standard deviation of the coeficients\n","    std_data = data.std()\n","    return std_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5ciMdc6an2U8"},"source":["def c_std(df1) :  #retourne une liste des means abs a partir d une channel decompposee (dataframe )\n","    coeffic =coef[1:]\n","    std=[]\n","    for i in range(len(coeffic)) :\n","       t=coeff_std(df1[coeffic[i]])\n","       std.append(t)\n","    return std"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4UslibKkq7rR"},"source":["##########################################\n","#                                        #\n","# Ratio of abs mean values of adjacent   #\n","#                                        #\n","##########################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aOxdXEZJkLFv"},"source":["def ratio(dt, output=False):\n","\n","    \n","    data = pd.DataFrame(dt,columns=['Values'])\n","     \n","    # get the mean of the absolute values\n","    data = data.abs().mean()\n","    # get a list of the index\n","    decimation_levels = list(data.index)\n","\n","    ratio_data=pd.Series(index=data.index)\n","    for level_no in range(0, len(decimation_levels)):\n","        # for the first decimation\n","        if level_no == 0:\n","            ratio_data.loc[decimation_levels[level_no]] = \\\n","            data.loc[decimation_levels[level_no]]/data.loc[decimation_levels[level_no+1]]\n","\n","        #for the last decimation\n","        elif level_no == len(decimation_levels)-1:\n","            ratio_data.loc[decimation_levels[level_no]] = \\\n","            data.loc[decimation_levels[level_no]]/data.loc[decimation_levels[level_no-1]]\n","        else:\n","            before = data.loc[decimation_levels[level_no-1]]\n","            after = data.loc[decimation_levels[level_no+1]]\n","            mean_data = (before+after)/2\n","\n","            ratio_data.loc[decimation_levels[level_no]] = \\\n","            data.loc[decimation_levels[level_no]]/mean_data\n","\n","         \n","    rt = ratio_data.tolist()\n","    \n","    \n","    return rt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dc2fFUIuq8KI"},"source":[" \n","# # def ratio(data, output=False):\n","#     # get the mean of the absolute values\n","#     data = data.abs().mean()\n","#     # get a list of the index\n","#     decimation_levels = coef\n","\n","#     ratio_data=pd.Series(index=coef)\n","#     for level_no in range(0, len(decimation_levels)):\n","#         # for the first decimation\n","#         if level_no == 0:\n","#             ratio_data.loc[decimation_levels[level_no]] = \\\n","#             data.loc[decimation_levels[level_no]]/data.loc[decimation_levels[level_no+1]]\n","\n","#         for the last decimation\n","#         elif level_no == len(decimation_levels)-1:\n","#             ratio_data.loc[decimation_levels[level_no]] = \\\n","#             data.loc[decimation_levels[level_no]]/data.loc[decimation_levels[level_no-1]]\n","#         else:\n","#             before = data.loc[decimation_levels[level_no-1]]\n","#             after = data.loc[decimation_levels[level_no+1]]\n","#             mean_data = (before+after)/2\n","\n","#             ratio_data.loc[decimation_levels[level_no]] = \\\n","#             data.loc[decimation_levels[level_no]]/mean_data\n","\n"," \n","    \n","#     return ratio_data\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EpTF36FB26U7"},"source":["def L_ratio(df1) :  #retourne une liste des means abs a partir d une channel decompposee (dataframe )\n","    coeffic =coef[1:]\n","    Cratio=[]\n","    for i in range(len(coeffic)) :\n","       t=ratio(df1[coeffic[i]])\n","       Cratio.append(t)\n","    return Cratio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L1mRvGS8kDlR"},"source":["\n","\n","##########################################\n","#                                        #\n","#            Entropy.                    #\n","#                                        #\n","##########################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dobE2-w9kOz9"},"source":["!git clone https://github.com/raphaelvallat/entropy.git entropy/\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UkExKVo0kP_T"},"source":["\n","from entropy.entropy import sample_entropy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eUFBVKyZkWMK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bktwcNzKZs_Q"},"source":["##########################################\n","#                                        #\n","#            def filtr +comps +feat      #\n","#                                        #\n","##########################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1lpifnQcrKxH"},"source":["#contruit df :input(file path , feature) => output(fd :filtred+ decompos + features )\n","def Fl_Ft(DATAfrm,f1,frow) :\n","    #f1=LR_EDF[0] \n","    coefficients=coef [1:]\n","    data = mne.io.read_raw_edf(f1)\n","    raw_data = data.get_data()\n","    chanlls=chanlls=channels_file(f1)\n","    # full dfM_abs \n","    #featurej= 'mean_abs'\n","    k=frow\n","        ##########################################################################\n","   # LFm=[]\n","   # for ch in range(len(chanlls)):\n","    #  for ft in range(len(coef)) :\n","       # # for fl in range(len(LFL)) :           \n","\n","    #          col_name =chanlls[ch]+'_' + coef[ft]+'_' + featurej\n","\n","      #        LFm.append(col_name) \n","    ##########################################################################\n","   # dfMM_abs= pd.DataFrame(columns=LFm)\n","    for i in  range(raw_data.shape[0]):\n","        pos=''\n","        print('\\n ----- \\n traitement de channel : ' ,i,'|',chanlls[i],'\\n') \n","        \n","        filt=filtrage_file_channel(f1,i)  #filtre 1\n","        filt2=filtrage_file_channel_FFT(filt) #filtre 2\n","        #decomps\n","        df1=decompose_signal_channel(filt2,i)\n","        #chanlls=channels_file(f1)\n","        #feature='mean_abs'\n","        df1=df1.drop('A6',1)\n","\n","        ###################  mean abs  ################## \n","        #LmAbs=m_abs(df1) #mean abs \n","        \n","        \n","        ################### std ################## \n","       # L_std = c_std(df1)\n","\n","        ###################  mean   ################## \n","        #Lmean = mn (df1)\n","        ###################  ratio ################## \n","\n","        Lratio = L_ratio(df1)                                         #ratio\n","        ###################  log_sum  ################## \n","       # Llgsm = l_sum (df1)\n","        #LFL = ['mean_abs','std', 'mean','ratio' ,'log_sum' ] \n","      \n","        #print('\\n ',featurej,' de channel : ',LmAbs,'\\n') \n","        for j in range(len(Lratio)) :\n","          #-------------------------#\n","        #  posj=chanlls[i]+'_'+coefficients[j]+'_'+'mean_abs'\n","         # print('\\n traitement de :\\n fichier : ',frow , '\\n', 'channal : ', i ,'\\n colone :',posj,'\\n') \n","         # DATAfrm.loc[k,posj]=LmAbs[j]\n","          #-------------------------#\n","        #  posj=chanlls[i]+'_'+coefficients[j]+'_'+'std'\n","         # print('\\n traitement de :\\n fichier : ',frow , '\\n', 'channal : ', i ,'\\n colone :',posj,'\\n') \n","         # DATAfrm.loc[k,posj]=L_std[j]\n","          #-------------------------#\n","        #  posj=chanlls[i]+'_'+coefficients[j]+'_'+'mean'\n","        #  print('\\n traitement de :\\n fichier : ',frow , '\\n', 'channal : ', i ,'\\n colone :',posj,'\\n') \n","          #DATAfrm.loc[k,posj]=Lmean[j]\n","          #-------------------------#\n","          posj=chanlls[i]+'_'+coefficients[j]+'_'+'ratio'                                         #ratio\n","          print('\\n traitement de :\\n fichier : ',frow , '\\n', 'channal : ', i ,'\\n colone :',posj,'\\n')                                       \n","          DATAfrm.loc[k,posj]=Lratio[j]                                         #ratio\n","        #-------------------------#\n","          # posj=chanlls[i]+'_'+coefficients[j]+'_'+'log_sum'\n","          # print('\\n traitement de :\\n fichier : ',frow , '\\n', 'channal : ', i ,'\\n colone :',posj,'\\n') \n","          # DATAfrm.loc[k,posj]=Llgsm[j]\n","\n","    return DATAfrm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UwvhVYvGKpbO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CFAoSH6_rc0g"},"source":["##########################################\n","#                                        #\n","#          put in  DATACHN          #\n","#                                        #\n","##########################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ISAfL0BBgfnI"},"source":[" #put in  DATACHN\n","#def put_DH(test0019,row) :\n"," # for i in range(len(test0019.columns)) :\n","  #        posi=test0019.columns[i]\n","   #       DATACHN.loc[row, posi]= test0019.loc[row, posi]\n","  #return DATACHN  \n","#for p_f in range(len(LR_EDF)) :\n","#  f=LR_EDF[p_f]\n","#  feat='mean_abs'\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1dUjU8n5jxYh"},"source":["DATACHN"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pu2ex2W0lngB"},"source":["\n","\n","for frow in range(len(LR_EDF)):\n","  \n","    \n","    print('\\n\\n---------\\n#############\\n#########\\n fichier : ' , frow , '########\\n########\\n########\\n---------\\n\\n')\n","\n","    #if ( frow != 1161)  : \n","      rf=LR_EDF[frow]\n","      DATACHN = Fl_Ft(DATACHN,rf,frow)\n","      # DATACHN=put_DH(test001,frow)\n","      #for i in range(len(test001.columns)) :\n","        #       posi=test001.columns[i]\n","        #      DATACHN.loc[frow, posi]= test001.loc[0, posi]\n","       \n","      if (frow==0) :         \n","        DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log00.csv')\n","     # if (frow==1161) :         \n","      #  DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log1161.csv')     \n","      elif (frow==100) :\n","        DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log100.csv')\n","      elif (frow==200) :\n","        DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log200.csv')\n","      elif (frow==300) :\n","        DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log300.csv')\n","      elif (frow==400) :\n","        DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log400.csv')\n","      elif (frow==500) :\n","        DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log500.csv')\n","      elif (frow==600) :\n","        DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log600.csv')\n","      elif (frow==700) :\n","        DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log700.csv')\n","      elif (frow==800) :\n","        DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log800.csv')\n","      elif (frow==900) :\n","        DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log900.csv')\n","      elif (frow==1000) :\n","        DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log1000.csv')\n","      elif (frow==1100) :\n","        DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log1100.csv')\n","      elif (frow==1200) :\n","        DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log1200.csv')\n","      elif (frow==1300) :\n","        DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log1300.csv')\n","      elif (frow==1400) :\n","        DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log1400.csv')\n","      elif (frow==1500) :\n","        DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log1500.csv')\n","      elif (frow==1600) :\n","        DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log1600.csv')\n","  \n","\n","\n","DATACHN.to_csv('/content/gdrive/MyDrive/DATAFINAl001/DF_rat_log1700.csv')\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fvMEmAaT3a5x"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y4yf49uepiNt"},"source":["DATACHN"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gz7WOLhz0slQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fhbnk4K7arWo"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TH5LFYHOayxJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yW53XmSna7qo"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UwlT5nNqj2Ve"},"source":[""],"execution_count":null,"outputs":[]}]}